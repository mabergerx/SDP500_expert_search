{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lpcPfLhtGRg4"
   },
   "source": [
    "## Pip installs, gsutil data getters and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eRsnwSSq_5-X",
    "outputId": "942d3ade-a9f0-4a37-bc76-c7baf085fff9"
   },
   "outputs": [],
   "source": [
    "# Libs\n",
    "! pip install sentence_transformers;\n",
    "!apt install libomp-dev;\n",
    "!pip3 install --upgrade faiss-gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZMAVwQwl_sch",
    "outputId": "d8bd52bf-f7bf-4534-b8b2-022aca06ac28"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import faiss\n",
    "from pprint import pprint\n",
    "import scipy\n",
    "from collections import Counter\n",
    "import ast\n",
    "from more_itertools import unique_everseen\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer('roberta-base-nli-stsb-mean-tokens')\n",
    "# res = faiss.StandardGpuResources()  # use a single GPU\n",
    "\n",
    "def dist2sim(d):\n",
    "    return 1 - d / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "daWvXqwFF_lw"
   },
   "source": [
    "## Functions for index and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uvh0L0Hq_0Av"
   },
   "outputs": [],
   "source": [
    "def load_relevant_index(type=\"separate_sbert\"):\n",
    "    index = None\n",
    "    if type == \"separate_sbert\":\n",
    "        index = faiss.read_index(\"Mapped_indeces/separate_embeddings_faiss.index\")\n",
    "    elif type == \"merged_sbert\":\n",
    "        index = faiss.read_index(\"Mapped_indeces/merged_embeddings_faiss.index\")\n",
    "    elif type == \"retro_merged_sbert\":\n",
    "        index = faiss.read_index(\"Mapped_indeces/retro_merged_embeddings_faiss.index\")\n",
    "    elif type == \"retro_separate_sbert\":\n",
    "        index = faiss.read_index(\"Mapped_indeces/retro_separate_embeddings_faiss.index\")\n",
    "    elif type == \"tfidf_svd\":\n",
    "        index = faiss.read_index(\"Mapped_indeces/tfidf_embeddings_faiss.index\")\n",
    "    elif type == \"pooled_bert\":\n",
    "        index = faiss.read_index(\"Mapped_indeces/mean_bert_faiss.index\")\n",
    "    elif type == \"pooled_glove\":\n",
    "        index = faiss.read_index(\"Mapped_indeces/glove_faiss.index\")\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnT6NO0HCQDr"
   },
   "outputs": [],
   "source": [
    "def load_data_and_authors(data_path=\"papers.csv, \n",
    "                          authors_path=\"authors.csv\"):\n",
    "    data = pd.read_csv(data_path)\n",
    "    authors = pd.read_csv(authors_path)\n",
    "    return data, authors\n",
    "\n",
    "data_and_authors = load_data_and_authors()\n",
    "data = data_and_authors[0]\n",
    "authors = data_and_authors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWpqlYTBoaw1"
   },
   "outputs": [],
   "source": [
    "def load_tidf_classifier():\n",
    "    return joblib.load(\"Mapped_indeces/tfidf_svd_transformer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWw2U0R-omuH"
   },
   "outputs": [],
   "source": [
    "# Was only needed to populate faiss with tf-idf, now just provided as loaded index\n",
    "# tfidf_clf = load_tidf_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyUVhMurGHdp"
   },
   "source": [
    "## Functions for field retrieval by paper or author id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0IQaGXvGC4ka"
   },
   "outputs": [],
   "source": [
    "def retrieve_author_by_id(author_id):\n",
    "    return authors[authors.id == int(author_id)]\n",
    "\n",
    "def get_abstract_by_id(id_):\n",
    "    return data[data.id == id_].abstract.values[0]\n",
    "\n",
    "def get_fos_by_id(id_):\n",
    "    return data[data.id == id_].fos.values[0]\n",
    "\n",
    "def get_title_by_id(id_):\n",
    "    return data[data.id == id_].title.values[0]\n",
    "\n",
    "def get_authors_by_id(id_):\n",
    "    try:\n",
    "        return data[data.id == id_].authors.values[0]\n",
    "    except:\n",
    "        print(id_)\n",
    "        return [{\"id\": -999999}]\n",
    "\n",
    "def get_first_author_by_id(id_):\n",
    "    authors = get_authors_by_id(id_)\n",
    "    return authors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zna77eb6_Def"
   },
   "outputs": [],
   "source": [
    "def retrieve_authorname_by_authorid(author_id):\n",
    "    return authors[authors.id == int(author_id)].name.values[0]\n",
    "\n",
    "def retrieve_pub_count_by_id(author_id):\n",
    "    return authors[authors.id == int(author_id)].n_pubs.values[0]\n",
    "\n",
    "def retrieve_cit_count_by_id(author_id):\n",
    "    return authors[authors.id == int(author_id)].n_citation.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5JRnEsUDH4T"
   },
   "outputs": [],
   "source": [
    "def get_information_by_id(id_, query, tfidf=False):\n",
    "    pprint(f\"Title: {get_title_by_id(id_)}\")\n",
    "    print(\"===\")\n",
    "    pprint(f\"Abstract: {get_abstract_by_id(id_)}\")\n",
    "    print(\"===\")\n",
    "    pprint(f\"Tags: {get_fos_by_id(id_)}\")\n",
    "    print(\"===\")\n",
    "    authors = get_authors_by_id(id_)\n",
    "    pprint(f\"Authors: {authors}\")\n",
    "    first_author = authors[0]\n",
    "    print(\"===\")\n",
    "    pprint(f\"First author {first_author['name']} relevant: {check_if_author_relevant(int(first_author['id']), query)}\")\n",
    "    print(\"===\")\n",
    "    pprint(f\"Approximately relevant: {check_if_author_relevant_approximate(int(first_author['id']), query, tfidf=tfidf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3BVPRg1-8vK"
   },
   "outputs": [],
   "source": [
    "def get_information_by_author_id(aid, query, tfidf=False):\n",
    "    pprint(f\"Name: {retrieve_authorname_by_authorid(aid)}\")\n",
    "    print(\"===\")\n",
    "    pprint(f\"Number of publications: {retrieve_pub_count_by_id(aid)}\")\n",
    "    print(\"===\")\n",
    "    pprint(f\"Number of citations: {retrieve_cit_count_by_id(aid)}\")\n",
    "    print(\"===\")\n",
    "    pprint(f\"Exactly relevant: {check_if_author_relevant(int(aid), query)}\")\n",
    "    print(\"===\")\n",
    "    pprint(f\"Approximately relevant: {check_if_author_relevant_approximate(int(aid), query, tfidf=tfidf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TlLuQCdHGbGf"
   },
   "source": [
    "## Functions for getting final author rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cfnasSOrDIy8"
   },
   "outputs": [],
   "source": [
    "def get_author_ranking_exact(query, index, k=10, tfidf=False):\n",
    "    query = query.lower()\n",
    "    results = retrieve_results(query, index, k, tfidf=tfidf)\n",
    "    candidate_papers = results[0]\n",
    "\n",
    "    # We remove duplicate authors for now, while preserving order (their highest position)\n",
    "    authors = list(unique_everseen([get_first_author_by_id(str(rid))[\"id\"] for rid in candidate_papers]))\n",
    "    relevancies = [check_if_author_relevant(int(a), query) for a in authors]\n",
    "\n",
    "    ranking = {}\n",
    "\n",
    "    for rank,(author, relevancy) in enumerate(zip(authors, relevancies)):\n",
    "        if author not in ranking.keys():\n",
    "            ranking[author] = {\"relevancy\": relevancy, \"rank\": rank}\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return ranking\n",
    "\n",
    "def get_author_ranking_approximate(query, index, k=10, similarity_threshold=0.7, tfidf=False):\n",
    "    query = query.lower()\n",
    "    results = retrieve_results(query, index, k, tfidf=tfidf)\n",
    "    \n",
    "    candidate_papers = results[0]\n",
    "    # We remove duplicate authors for now, while preserving order (their highest position)\n",
    "    authors = list(unique_everseen([get_first_author_by_id(str(rid))[\"id\"] for rid in candidate_papers]))\n",
    "    relevancies = [check_if_author_relevant_approximate(int(a), query, similarity_threshold, tfidf=tfidf) for a in authors]\n",
    "\n",
    "    ranking = {}\n",
    "\n",
    "    for rank,(author, relevancy) in enumerate(zip(authors, relevancies)):\n",
    "        if author not in ranking.keys():\n",
    "            ranking[author] = {\"relevancy\": relevancy, \"rank\": rank}\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2XtMb8iAtON"
   },
   "outputs": [],
   "source": [
    "def get_author_ranking_average_exact(query, index, k=10, tfidf=False):\n",
    "    query = query.lower()\n",
    "    results = retrieve_results_average(query, index, k, tfidf=tfidf)\n",
    "    candidate_authors = list(unique_everseen(results[0]))\n",
    "\n",
    "    # We remove duplicate authors for now, while preserving order (their highest position)\n",
    "    # authors = list(unique_everseen([get_first_author_by_id(str(rid))[\"id\"] for rid in candidate_papers]))\n",
    "    relevancies = [check_if_author_relevant(int(a), query) for a in candidate_authors]\n",
    "\n",
    "    ranking = {}\n",
    "\n",
    "    for rank,(author, relevancy) in enumerate(zip(candidate_authors, relevancies)):\n",
    "        if author not in ranking.keys():\n",
    "            ranking[author] = {\"relevancy\": relevancy, \"rank\": rank}\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return ranking\n",
    "\n",
    "def get_author_ranking_average_approximate(query, index, k=10, similarity_threshold=0.7, tfidf=False):\n",
    "    query = query.lower()\n",
    "    results = retrieve_results_average(query, index, k, tfidf=tfidf)\n",
    "    \n",
    "    candidate_authors = list(unique_everseen(results[0]))\n",
    "    # We remove duplicate authors for now, while preserving order (their highest position)\n",
    "    # authors = list(unique_everseen([get_first_author_by_id(str(rid))[\"id\"] for rid in candidate_papers]))\n",
    "    relevancies = [check_if_author_relevant_approximate(int(a), query, similarity_threshold, tfidf=tfidf) for a in candidate_authors]\n",
    "\n",
    "    ranking = {}\n",
    "\n",
    "    for rank,(author, relevancy) in enumerate(zip(candidate_authors, relevancies)):\n",
    "        if author not in ranking.keys():\n",
    "            ranking[author] = {\"relevancy\": relevancy, \"rank\": rank}\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XkmK__goDLtB"
   },
   "outputs": [],
   "source": [
    "def prune_results_for_authors_wo_tags(results, query, how_many=10):\n",
    "    ids = results[0]\n",
    "    distances = results[1]\n",
    "\n",
    "    relevant_ids = []\n",
    "    relevant_distances = []\n",
    "    # For now, I check if the first author is not in the set, I throw the paper away, because I now\n",
    "    # only look at first author for evaluation. But later if I have another strategy for retrieving author per paper\n",
    "    # we can change this logic back to \"all authors not in the set\".\n",
    "    for rid, rd in zip(ids, distances):\n",
    "        authors = [a[\"id\"] for a in get_authors_by_id(str(rid))]\n",
    "        relevancy = [check_if_author_relevant(int(a), query) for a in authors]\n",
    "        # if relevancy != ['Not in the dataset or no tags present!']*len(relevancy):\n",
    "        #     relevant_ids.append(rid)\n",
    "        #     relevant_distances.append(rd)\n",
    "        if relevancy[0] != 'Not in the dataset or no tags present!':\n",
    "            relevant_ids.append(rid)\n",
    "            relevant_distances.append(rd)\n",
    "\n",
    "    return relevant_ids[:how_many], relevant_distances[:how_many]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eak4NGNZ9JZI"
   },
   "outputs": [],
   "source": [
    "def prune_results_for_authors_wo_tags_average(results, query, how_many=10):\n",
    "    ids = results[0]\n",
    "    distances = results[1]\n",
    "\n",
    "    relevant_ids = []\n",
    "    relevant_distances = []\n",
    "    for aid, ad in zip(ids, distances):\n",
    "        relevancy = check_if_author_relevant(int(aid), query)\n",
    "\n",
    "        if relevancy != 'Not in the dataset or no tags present!':\n",
    "            relevant_ids.append(aid)\n",
    "            relevant_distances.append(ad)\n",
    "\n",
    "    return relevant_ids[:how_many], relevant_distances[:how_many]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZaXH0X6EGn_h"
   },
   "source": [
    "## Functions for the Faiss index search and utilities for the paper retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JrRirNK9DXD6"
   },
   "outputs": [],
   "source": [
    "def get_most_similar_ids(query, index, k=10, tfidf_classifier=None):\n",
    "    # First, embed the query, normalize the vector and convert to float32\n",
    "\n",
    "    if tfidf_classifier:\n",
    "        query_emb = tfidf_classifier.transform([query])[0]\n",
    "        normalized_query = np.float32([query_emb])[0]\n",
    "    else:\n",
    "        query_emb = embedder.encode([query])[0]\n",
    "        normalized_query = np.float32(normalize([query_emb])[0])\n",
    "\n",
    "    assert type(normalized_query[0]).__name__ == 'float32'\n",
    "\n",
    "    #Next, run the index search\n",
    "    s = time.time()\n",
    "    dists, idxs = index.search(np.array([normalized_query]), k)\n",
    "    # print(\"Search execution time:\")\n",
    "    # print((time.time() - s), \"s.\")\n",
    "    # print(\"IDS, sorted by similarity:\")\n",
    "    # print(idxs[0])\n",
    "    # print('Similarity scores:')\n",
    "    # print(dist2sim(dists[0]))\n",
    "    return idxs[0], dist2sim(dists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9OqCwE-NEpWy"
   },
   "outputs": [],
   "source": [
    "def retrieve_results(query, index, k=10, verbose=False, tfidf=False):\n",
    "    initial_retrieval = k*5\n",
    "    s = time.time()\n",
    "    if tfidf:\n",
    "        most_similar_raw = get_most_similar_ids(query, index, initial_retrieval, tfidf_clf)\n",
    "    else:\n",
    "        most_similar_raw = get_most_similar_ids(query, index, initial_retrieval)\n",
    "    s1 = time.time()\n",
    "    pruned = prune_results_for_authors_wo_tags(most_similar_raw, query, k)\n",
    "    s2 = time.time()\n",
    "    if verbose:\n",
    "        print(f\"Full search execution time: {time.time() - s} seconds\")\n",
    "        print(f\"from which {s1-s} s. in the search and {s2 - s1} s. in the pruning.\")\n",
    "        print(\"===\")\n",
    "        print(\"Pruned IDS, sorted by similarity:\")\n",
    "        print(pruned[0])\n",
    "        print('Similarity scores:')\n",
    "        print(pruned[1])\n",
    "    return pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvPGc0GZ8lFc"
   },
   "outputs": [],
   "source": [
    "def retrieve_results_average(query, index, k=10, verbose=False, tfidf=False):\n",
    "    initial_retrieval = k*5\n",
    "    s = time.time()\n",
    "    if tfidf:\n",
    "        most_similar_raw = get_most_similar_ids(query, index, initial_retrieval, tfidf_clf)\n",
    "    else:\n",
    "        most_similar_raw = get_most_similar_ids(query, index, initial_retrieval)\n",
    "    s1 = time.time()\n",
    "    pruned = prune_results_for_authors_wo_tags_average(most_similar_raw, query, k)\n",
    "    s2 = time.time()\n",
    "    if verbose:\n",
    "        print(f\"Full search execution time: {time.time() - s} seconds\")\n",
    "        print(f\"from which {s1-s} s. in the search and {s2 - s1} s. in the pruning.\")\n",
    "        print(\"===\")\n",
    "        print(\"Pruned author IDS, sorted by similarity:\")\n",
    "        print(pruned[0])\n",
    "        print('Similarity scores:')\n",
    "        print(pruned[1])\n",
    "    return pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQ1KcvD_Fbst"
   },
   "outputs": [],
   "source": [
    "def calculate_distances_from_query_to_fos(query, fos_tags, tfidf_classifier=None):\n",
    "\n",
    "    if tfidf_classifier:\n",
    "        fos_tag_embeddings = tfidf_classifier.transform(fos_tags)\n",
    "        query_emb = tfidf_classifier.transform([query])[0]\n",
    "    else:\n",
    "        fos_tag_embeddings = embedder.encode(fos_tags)\n",
    "        query_emb = embedder.encode([query])[0]\n",
    "\n",
    "    distances = [ 1- scipy.spatial.distance.cdist([query_emb], [fos_tag_embedding], 'cosine')[0][0] for fos_tag_embedding in fos_tag_embeddings]\n",
    "\n",
    "    return [(ft, d) for ft, d in zip(fos_tags, distances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RsNtYJk2Fy-t"
   },
   "outputs": [],
   "source": [
    "def retrieve_author_tags(author_id):\n",
    "    try:\n",
    "        return ast.literal_eval(authors[authors.id == author_id].tags.values[0])\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bv87cvsyG3cG"
   },
   "source": [
    "## Functions for checking relevancy of a certain author with regard to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NQKEe1eF1qg"
   },
   "outputs": [],
   "source": [
    "def check_if_author_relevant(author_id, query):\n",
    "    query = query.lower()\n",
    "    tags = [t['t'].lower() for t in retrieve_author_tags(author_id)]\n",
    "    if tags:\n",
    "        if query in tags:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return \"Not in the dataset or no tags present!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTFtKhuFF6WO"
   },
   "outputs": [],
   "source": [
    "def check_if_author_relevant_approximate(author_id, query, similarity_threshold=0.7, tfidf=False):\n",
    "    query = query.lower()\n",
    "    tags = [t['t'].lower() for t in retrieve_author_tags(author_id)]\n",
    "    if tfidf:\n",
    "        distances = calculate_distances_from_query_to_fos(query, tags, tfidf_clf)\n",
    "    else:\n",
    "        distances = calculate_distances_from_query_to_fos(query, tags)\n",
    "    similar = [d for d in distances if d[1] > similarity_threshold]\n",
    "    # print(\"Approx. similar:\", similar)\n",
    "    if similar:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQveW-eWHAqK"
   },
   "source": [
    "# Actual retrieval examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-kR_KczEv8o"
   },
   "outputs": [],
   "source": [
    "queries = ['cluster analysis', 'Image segmentation', 'Parallel algorithm', 'Monte Carlo method',\n",
    "           'Convex optimization', 'Dimensionality reduction', 'Facial recognition system', \n",
    "           'k-nearest neighbors algorithm', 'Hierarchical clustering', 'Automatic summarization',\n",
    "           'Dynamic programming', 'Genetic algorithm', 'Human-computer interaction', 'Categorial grammar', \n",
    "           'Semantic Web', 'fuzzy logic', 'image restoration', 'generative model', 'search algorithm',\n",
    "           'sample size determination', 'anomaly detection', 'sentiment analysis', 'semantic similarity',\n",
    "           'world wide web', 'gibbs sampling', 'user interface', 'belief propagation', 'interpolation', \n",
    "           'wavelet transform', 'transfer of learning', 'topic model', 'clustering high-dimensional data', \n",
    "           'game theory', 'biometrics', 'constraint satisfaction', 'combinatorial optimization', 'speech processing',\n",
    "           'multi-agent system', 'mean field theory', 'social network', 'lattice model', 'automatic image annotation',\n",
    "           'computational geometry', 'Evolutionary algorithm', 'web search query', 'eye tracking', 'query optimization',\n",
    "           'logic programming', 'Hyperspectral imaging', 'Bayesian statistics', 'kernel density estimation',\n",
    "           'learning to rank', 'relational database', 'activity recognition', 'wearable computer', 'big data', \n",
    "           'ensemble learning', 'wordnet', 'medical imaging', 'deconvolution', 'Latent Dirichlet allocation', \n",
    "           'Euclidian distance', 'web service', 'multi-task learning', 'Linear separability', 'OWL-S',\n",
    "           'Wireless sensor network', 'Semantic role labeling', 'Continuous-time Markov chain', \n",
    "           'Open Knowledge Base Connectivity', 'Propagation of uncertainty', 'Fast Fourier transform', \n",
    "           'Security token', 'Novelty detection', 'semantic grid', 'Knowledge extraction', \n",
    "           'Computational biology', 'Web 2.0', 'Network theory', 'Video denoising', 'Quantum information science',\n",
    "           'Color quantization', 'social web', 'entity linking', 'information privacy', 'random forest', \n",
    "           'cloud computing', 'Knapsack problem', 'Linear algebra', 'batch processing', 'rule induction', \n",
    "           'Uncertainty quantification', 'Computer architecture', 'Best-first search', 'Gaussian random field',\n",
    "           'Support vector machine', 'ontology language', 'machine translation', 'middleware', 'Newton\\'s method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ueUvhsuxE32z"
   },
   "outputs": [],
   "source": [
    "index = load_relevant_index(\"separate_sbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I21rtZwyFMXb"
   },
   "outputs": [],
   "source": [
    "query = \"world wide web\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "A2-gUldUEz4W",
    "outputId": "545cdbd6-df98-453e-b6bc-9794f45e30ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full search execution time: 1.5033385753631592 seconds\n",
      "from which 0.8180646896362305 s. in the search and 0.6852731704711914 s. in the pruning.\n",
      "===\n",
      "Pruned IDS, sorted by similarity:\n",
      "[2154085356, 1601547964, 2395256202, 1568893392, 2768317741, 2059713800, 2147164982, 2138350977, 2119012894, 2157327941]\n",
      "Similarity scores:\n",
      "[0.8862335, 0.75639015, 0.7390435, 0.7349443, 0.7105715, 0.6853581, 0.6767964, 0.6290454, 0.6205123, 0.6062963]\n"
     ]
    }
   ],
   "source": [
    "retrieve_results(query.lower(), index, k=10, verbose=True, tfidf=False);\n",
    "# get_most_similar_ids(query, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bcb9zGmEFALL",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Title: Data Clustering: Theory, Algorithms, and Applications'\n",
      "===\n",
      "('Abstract: Preface Part I. Clustering, Data and Similarity Measures: 1. Data '\n",
      " 'clustering 2. DataTypes 3. Scale conversion 4. Data standardization and '\n",
      " 'transformation 5. Data visualization 6. Similarity and dissimilarity '\n",
      " 'measures Part II. Clustering Algorithms: 7. Hierarchical clustering '\n",
      " 'techniques 8. Fuzzy clustering algorithms 9. Center Based Clustering '\n",
      " 'Algorithms 10. Search based clustering algorithms 11. Graph based clustering '\n",
      " 'algorithms 12. Grid based clustering algorithms 13. Density based clustering '\n",
      " 'algorithms 14. Model based clustering algorithms 15. Subspace clustering 16. '\n",
      " 'Miscellaneous algorithms 17. Evaluation of clustering algorithms Part III. '\n",
      " 'Applications of Clustering: 18. Clustering gene expression data Part IV. '\n",
      " 'Matlab and C++ for Clustering: 19. Data clustering in Matlab 20. Clustering '\n",
      " 'in C/C++ A. Some clustering algorithms B. Thekd-tree data structure C. '\n",
      " 'Matlab Codes D. C++ Codes Subject index Author index.')\n",
      "===\n",
      "(\"Tags: [{'name': 'CURE data clustering algorithm', 'w': 0.771316051}, \"\n",
      " \"{'name': 'Cluster analysis', 'w': 0.802325666}, {'name': 'Fuzzy clustering', \"\n",
      " \"'w': 0.7736898}, {'name': 'k-medians clustering', 'w': 0.7570339}, {'name': \"\n",
      " \"'Correlation clustering', 'w': 0.789815247}, {'name': 'Algorithm', 'w': \"\n",
      " \"0.400741547}, {'name': 'Machine learning', 'w': 0.441110164}, {'name': \"\n",
      " \"'Canopy clustering algorithm', 'w': 0.759673536}, {'name': 'Single-linkage \"\n",
      " \"clustering', 'w': 0.7600901}, {'name': 'Artificial intelligence', 'w': 0.0}, \"\n",
      " \"{'name': 'Computer science', 'w': 0.379517585}, {'name': 'Pattern \"\n",
      " \"recognition', 'w': 0.449274063}, {'name': 'Brown clustering', 'w': \"\n",
      " '0.7470003}]')\n",
      "===\n",
      "(\"Authors: [{'name': 'Guojun Gan', 'id': '2136847405'}, {'name': 'Chaoqun Ma', \"\n",
      " \"'id': '2561718351'}, {'name': 'Jianhong Wu', 'id': '2106660240'}]\")\n",
      "===\n",
      "'First author Guojun Gan relevant: True'\n",
      "===\n",
      "'Approximately relevant: True'\n"
     ]
    }
   ],
   "source": [
    "get_information_by_id(\"1594924988\", query, tfidf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPqNZU9Y33PS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Name: Aristides Gionis'\n",
      "===\n",
      "'Number of publications: 35'\n",
      "===\n",
      "'Number of citations: 4256'\n",
      "===\n",
      "'Exactly relevant: True'\n",
      "===\n",
      "'Approximately relevant: True'\n"
     ]
    }
   ],
   "source": [
    "get_information_by_author_id(\"2593877498\", \"cluster analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uim4LeXAHVwe"
   },
   "outputs": [],
   "source": [
    "get_author_ranking_exact(query, index, tfidf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'t': 'Nearest neighbor search'},\n",
       " {'t': 'Random testing'},\n",
       " {'t': 'Computational complexity theory'},\n",
       " {'t': 'Scalability'},\n",
       " {'t': 'Markov process'},\n",
       " {'t': 'Correlation clustering'},\n",
       " {'t': 'Best-effort delivery'},\n",
       " {'t': 'Algorithm'},\n",
       " {'t': 'Metasearch engine'},\n",
       " {'t': 'Sequence'},\n",
       " {'t': 'Bioinformatics'},\n",
       " {'t': 'Matrix decomposition'},\n",
       " {'t': 'Bayesian information criterion'},\n",
       " {'t': 'Data collection'},\n",
       " {'t': 'Approximation algorithm'},\n",
       " {'t': 'Time series'},\n",
       " {'t': 'DNA'},\n",
       " {'t': 'Computational biology'},\n",
       " {'t': 'Ranking'},\n",
       " {'t': 'External Data Representation'},\n",
       " {'t': 'Randomized algorithm'},\n",
       " {'t': 'Boolean algebra'},\n",
       " {'t': 'Data processing'},\n",
       " {'t': 'Regular expression'},\n",
       " {'t': 'Environmental science'},\n",
       " {'t': 'Wireless sensor network'},\n",
       " {'t': 'Collaborative filtering'},\n",
       " {'t': 'Data structure'},\n",
       " {'t': 'Data analysis'},\n",
       " {'t': 'Minimum description length'},\n",
       " {'t': 'Database'},\n",
       " {'t': 'Network topology'},\n",
       " {'t': 'Resampling'},\n",
       " {'t': 'Order theory'},\n",
       " {'t': 'Cluster analysis'},\n",
       " {'t': 'Total order'},\n",
       " {'t': 'Sliding window protocol'},\n",
       " {'t': 'Evaluation'},\n",
       " {'t': 'Digital library'},\n",
       " {'t': 'Sensor'},\n",
       " {'t': 'Database design'},\n",
       " {'t': 'Information retrieval'},\n",
       " {'t': 'Anchor text'},\n",
       " {'t': 'XML database'},\n",
       " {'t': 'Telecommunications'},\n",
       " {'t': 'Search engine'},\n",
       " {'t': 'Chi-square test'},\n",
       " {'t': 'Regression analysis'},\n",
       " {'t': 'Data'},\n",
       " {'t': 'Information processing'},\n",
       " {'t': 'Probabilistic analysis of algorithms'},\n",
       " {'t': 'Regression'},\n",
       " {'t': 'Correlation dimension'},\n",
       " {'t': 'XML'},\n",
       " {'t': 'Merge'},\n",
       " {'t': 'Group method of data handling'},\n",
       " {'t': 'Analysis of algorithms'},\n",
       " {'t': 'Data mining'},\n",
       " {'t': 'Distributed computing'},\n",
       " {'t': 'Fractal dimension'},\n",
       " {'t': 'Anomaly detection'},\n",
       " {'t': 'Matrix method'},\n",
       " {'t': 'Probability'},\n",
       " {'t': 'Matrix multiplication'},\n",
       " {'t': 'Greedy algorithm'},\n",
       " {'t': 'Statistical model'},\n",
       " {'t': 'Expressive power'},\n",
       " {'t': 'Markov chain'},\n",
       " {'t': 'Partially ordered set'},\n",
       " {'t': 'Swap'},\n",
       " {'t': 'Upper and lower bounds'},\n",
       " {'t': 'Bayesian network'},\n",
       " {'t': 'Empirical evidence'},\n",
       " {'t': 'Information extraction'},\n",
       " {'t': 'Systems modeling'},\n",
       " {'t': 'Unimodality'},\n",
       " {'t': 'Principal component analysis'},\n",
       " {'t': 'Tree structure'},\n",
       " {'t': 'Decision tree model'},\n",
       " {'t': 'Linear programming'},\n",
       " {'t': 'Metadata'},\n",
       " {'t': 'Hash table'},\n",
       " {'t': 'Treewidth'},\n",
       " {'t': 'Knowledge extraction'},\n",
       " {'t': 'Monotonic function'},\n",
       " {'t': 'Permutation'},\n",
       " {'t': 'Whole genome sequencing'},\n",
       " {'t': 'Combinatorial optimization'},\n",
       " {'t': 'Dynamic programming'},\n",
       " {'t': 'Segmentation'},\n",
       " {'t': 'Lp space'},\n",
       " {'t': 'Satisfiability'},\n",
       " {'t': 'Correspondence problem'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_author_tags(2593877498)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5TmFEsNVk2i"
   },
   "source": [
    "# Author re-ranking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6QEzZW0lVq-E"
   },
   "outputs": [],
   "source": [
    "i, d = get_most_similar_ids(query.lower(), index, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IlyNbr4UXaCp",
    "outputId": "2ca50ded-6523-4fc1-f40a-b4499b449a6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in d if x > 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "id": "W4hlJKA3aFLT",
    "outputId": "03dd4a77-5dad-4ca9-ecf2-f27c8989c25c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6774728 , 0.6267048 , 0.6201817 , 0.56027675, 0.5555264 ,\n",
       "       0.55523175, 0.54782987, 0.52863693, 0.52390087, 0.5218121 ,\n",
       "       0.51709706, 0.5156915 , 0.51461625, 0.5075133 , 0.49405396,\n",
       "       0.49302465, 0.49144435, 0.49137604, 0.49063826, 0.48952   ,\n",
       "       0.48618758, 0.48452473, 0.48440003, 0.47892427, 0.47764754,\n",
       "       0.47451985, 0.47381836, 0.46670514, 0.46172583, 0.46117938,\n",
       "       0.4595275 , 0.45459133, 0.45347226, 0.45202821, 0.4520086 ,\n",
       "       0.4491104 , 0.44467467, 0.4441229 , 0.4357288 , 0.43286896,\n",
       "       0.43240428, 0.4315712 , 0.43128896, 0.42991185, 0.42907357,\n",
       "       0.42684197, 0.4264232 , 0.4248494 , 0.42293078, 0.4221788 ,\n",
       "       0.42216408, 0.4211011 , 0.41978258, 0.41809082, 0.41717345,\n",
       "       0.41616   , 0.41365236, 0.41316593, 0.41274178, 0.41271734,\n",
       "       0.41213948, 0.4115572 , 0.4114157 , 0.41096544, 0.4065985 ,\n",
       "       0.40382224, 0.40341467, 0.40215343, 0.4009413 , 0.39993775,\n",
       "       0.3994406 , 0.39857626, 0.39777416, 0.3973974 , 0.39488107,\n",
       "       0.39171767, 0.38969278, 0.38697827, 0.3869484 , 0.38569117,\n",
       "       0.3854751 , 0.38414514, 0.38208067, 0.37985277, 0.3771609 ,\n",
       "       0.37492567, 0.37108725, 0.36959207, 0.36880553, 0.36854643,\n",
       "       0.36848795, 0.36728328, 0.36712104, 0.3669803 , 0.36693943,\n",
       "       0.36684048, 0.36512244, 0.3648486 , 0.3643937 , 0.3634755 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6KaTdgfEiwU1"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MIKN5GkHU_8k",
    "outputId": "d0b28be8-4fe4-4460-f7bb-021f7203f96c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_pub_count_by_id(2589367414)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LhXko-XxZt8u"
   },
   "outputs": [],
   "source": [
    "AVERAGE_N_PUBS = int(authors.n_pubs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVERAGE_N_PUBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.053889222667731"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.60771036 * math.log(2+100*(58/500), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.25 9.45   \n",
    "0.252 5.49\n",
    "5.85  15.94\n",
    "11.02 21\n",
    "16    26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64857.25838543333"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([math.exp(score) for score in [11.079944109239786]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.4131591025766"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFoqld_FcDf5"
   },
   "outputs": [],
   "source": [
    "def create_score_author_dict(query, retrieved_paper_ids, retrieved_distances, strategy=\"uniform\", normalized=False, average_pub_count=58, \n",
    "                            normalization_alpha=1, extra_normalization_term=10):\n",
    "    # authors = [[item[\"id\"] for item in get_authors_by_id(str(i))] for i in retrieved_paper_ids]\n",
    "    # return authors\n",
    "    # scores_per_paper = [(score / len(list(authors_))) for score, authors_ in zip(retrieved_distances, authors)]\n",
    "    # return scores_per_paper\n",
    "\n",
    "    def expCombSUM(list_of_scores):\n",
    "        return sum([math.exp(score) for score in list_of_scores])\n",
    "    \n",
    "    def normalize_score(score, l_pro, average_l=average_pub_count, alpha=normalization_alpha):\n",
    "        normalized_score = score * math.log(1 + alpha * (average_l / (l_pro+extra_normalization_term)), 2)\n",
    "        return normalized_score\n",
    "\n",
    "    scores_per_author = defaultdict(list)\n",
    "    for pi, score in zip(retrieved_paper_ids, retrieved_distances):\n",
    "        # Prune only for author that exist in our data.\n",
    "        authors = [item[\"id\"] for item in get_authors_by_id(str(pi)) if check_if_author_relevant(int(item[\"id\"]), query) != 'Not in the dataset or no tags present!']\n",
    "        if authors:\n",
    "            if strategy == \"uniform\":\n",
    "                score_per_author = score / len(authors)\n",
    "                for author in authors:\n",
    "                    if normalized:\n",
    "                        pub_count = retrieve_pub_count_by_id(int(author))\n",
    "                        normalized_score = normalize_score(score_per_author, pub_count)\n",
    "                        scores_per_author[author].append(normalized_score)\n",
    "                    else:\n",
    "                        scores_per_author[author].append(score_per_author)\n",
    "            elif strategy == \"binary\":\n",
    "                score_per_author = score\n",
    "                for author in authors:\n",
    "                    if normalized:\n",
    "                        pub_count = retrieve_pub_count_by_id(int(author))\n",
    "                        normalized_score = normalize_score(score_per_author, pub_count)\n",
    "                        scores_per_author[author].append(normalized_score)\n",
    "                    else:\n",
    "                        scores_per_author[author].append(score_per_author)\n",
    "            elif strategy == \"descending\":\n",
    "                decay_factor = 1\n",
    "                for author in authors:\n",
    "                    if normalized:\n",
    "                        score_d = score*decay_factor\n",
    "                        pub_count = retrieve_pub_count_by_id(int(author))\n",
    "                        normalized_score = normalize_score(score_d, pub_count)\n",
    "                        scores_per_author[author].append(normalized_score)\n",
    "                        decay_factor -= 0.2\n",
    "                    else:\n",
    "                        scores_per_author[author].append(score*decay_factor)\n",
    "                        decay_factor -= 0.2\n",
    "            elif strategy == \"parabolic\":\n",
    "                #  TODO: here we did not yet write the normalization code because we do not run it for this config.\n",
    "                decay_factor = 0.8\n",
    "                scores_per_author[authors[0]].append(score)\n",
    "                scores_per_author[authors[-1]].append(score)\n",
    "                for author in authors[1:-1]:\n",
    "                    scores_per_author[author].append(score*decay_factor)\n",
    "                    decay_factor -= 0.2\n",
    "            # scores = {author : score_per_author for author in authors}\n",
    "            # scores_per_paper[pi] = scores\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    authorship_scores = {k : expCombSUM(v) for k, v in scores_per_author.items()}\n",
    "\n",
    "    return authorship_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "43_RSIKXcbdc"
   },
   "outputs": [],
   "source": [
    "aa = create_score_author_dict(query, i, d, \"binary\", normalized=True, normalization_alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'world wide web'"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwa-WF0dd_ZR"
   },
   "outputs": [],
   "source": [
    "def produce_authors_ranking(authorship_scores):\n",
    "    sortd = [(k, v) for k, v in sorted(authorship_scores.items(), key=lambda item: item[1], reverse=True)]\n",
    "    return sortd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZe3zOmsBs40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1243699091', 160.96043931062977),\n",
       " ('2687102544', 87.25080609385644),\n",
       " ('2308609296', 80.47302732308727),\n",
       " ('2700131745', 72.65723702922999),\n",
       " ('836368383', 68.42711735563111),\n",
       " ('1829258144', 62.595710419009194),\n",
       " ('2345687710', 58.51570204196498),\n",
       " ('2114878113', 54.54940569852606),\n",
       " ('2141172858', 41.46401206334932),\n",
       " ('2043954528', 39.19098392418984)]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "produce_authors_ranking(aa)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwPqrlBouhv9"
   },
   "outputs": [],
   "source": [
    "get_information_by_author_id(\"2151264347\", query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RyoVBX5aB4lo"
   },
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsIwq0dx3ogE"
   },
   "outputs": [],
   "source": [
    "def get_author_ranking_exact_v2(query, index, k=10, tfidf=False, strategy=\"uniform\", \n",
    "                                normalized=False, norm_alpha=100, extra_term=10):\n",
    "    \n",
    "    if tfidf:\n",
    "        i, d = get_most_similar_ids(query.lower(), index, 100, tfidf_clf)\n",
    "    else:\n",
    "        i, d = get_most_similar_ids(query.lower(), index, 100)\n",
    "\n",
    "    author_score_dict = create_score_author_dict(query, i, d, strategy, \n",
    "                                                 normalized=normalized, normalization_alpha=norm_alpha, extra_normalization_term=extra_term)\n",
    "\n",
    "    top_n = produce_authors_ranking(author_score_dict)[:k]\n",
    "\n",
    "    relevancies = [check_if_author_relevant(int(aid), query) for aid, _ in top_n]\n",
    "\n",
    "    ranking = {}\n",
    "\n",
    "    for rank, (author, relevancy) in enumerate(zip([a[0] for a in top_n], relevancies)):\n",
    "        if author not in ranking.keys():\n",
    "            ranking[author] = {\"relevancy\": relevancy, \"rank\": rank}\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return ranking\n",
    "\n",
    "def get_author_ranking_approximate_v2(query, index, k=10, similarity_threshold=0.7, tfidf=False, strategy=\"uniform\", \n",
    "                                      normalized=False, norm_alpha=100, extra_term=10):\n",
    "    \n",
    "    if tfidf:\n",
    "        i, d = get_most_similar_ids(query.lower(), index, 100, tfidf_clf)\n",
    "    else:\n",
    "        i, d = get_most_similar_ids(query.lower(), index, 100)\n",
    "\n",
    "    author_score_dict = create_score_author_dict(query, i, d, strategy, \n",
    "                                                 normalized=normalized, normalization_alpha=norm_alpha, extra_normalization_term=extra_term)\n",
    "\n",
    "    top_n = produce_authors_ranking(author_score_dict)[:k]\n",
    "    \n",
    "    relevancies = [check_if_author_relevant_approximate(int(aid), query, similarity_threshold, tfidf=tfidf) for aid, _ in top_n]\n",
    "\n",
    "    ranking = {}\n",
    "\n",
    "    for rank, (author, relevancy) in enumerate(zip([a[0] for a in top_n], relevancies)):\n",
    "        if author not in ranking.keys():\n",
    "            ranking[author] = {\"relevancy\": relevancy, \"rank\": rank}\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTPVngvk4s0I"
   },
   "outputs": [],
   "source": [
    "norm_semantic_role_labeling = get_author_ranking_exact_v2(\"gibbs sampling\", index, strategy=\"binary\", tfidf=False, normalized=True, extra_term=0, norm_alpha=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_norm_semantic_role_labeling = get_author_ranking_exact_v2(\"gibbs sampling\", index, strategy=\"binary\", tfidf=False, normalized=False, extra_term=100, norm_alpha=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2675564889': {'relevancy': True, 'rank': 0},\n",
       " '2568602334': {'relevancy': True, 'rank': 1},\n",
       " '2671169580': {'relevancy': False, 'rank': 2},\n",
       " '2132896614': {'relevancy': True, 'rank': 3},\n",
       " '2304614720': {'relevancy': True, 'rank': 4},\n",
       " '2673417165': {'relevancy': True, 'rank': 5},\n",
       " '2621515602': {'relevancy': False, 'rank': 6},\n",
       " '2106178016': {'relevancy': False, 'rank': 7},\n",
       " '2564840304': {'relevancy': False, 'rank': 8},\n",
       " '2236759972': {'relevancy': False, 'rank': 9}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_semantic_role_labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'183722240': {'relevancy': True, 'rank': 0},\n",
       " '2149454608': {'relevancy': True, 'rank': 1},\n",
       " '2347934206': {'relevancy': True, 'rank': 2},\n",
       " '2056153991': {'relevancy': True, 'rank': 3},\n",
       " '2435751034': {'relevancy': True, 'rank': 4},\n",
       " '2123777986': {'relevancy': False, 'rank': 5},\n",
       " '1964890520': {'relevancy': False, 'rank': 6},\n",
       " '2635064073': {'relevancy': True, 'rank': 7},\n",
       " '2131550435': {'relevancy': True, 'rank': 8},\n",
       " '2304614720': {'relevancy': True, 'rank': 9}}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_norm_semantic_role_labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSEoYou45DMb"
   },
   "outputs": [],
   "source": [
    "def calculate_average_npubs_per_ranking(ranking):\n",
    "    n_pubs = [retrieve_pub_count_by_id(author) for author in ranking.keys()]\n",
    "    return np.mean(n_pubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_average_npubs_per_ranking(norm_semantic_role_labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205.9"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_average_npubs_per_ranking(not_norm_semantic_role_labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_ncitation_per_ranking(ranking):\n",
    "    n_cit = [retrieve_cit_count_by_id(author) for author in ranking.keys()]\n",
    "    return np.mean(n_cit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268.8"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_average_ncitation_per_ranking(norm_semantic_role_labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15278.9"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_average_ncitation_per_ranking(not_norm_semantic_role_labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sp0gGQTCzmJy"
   },
   "outputs": [],
   "source": [
    "# We have to do pruning here too, and remove authors that are not in the dataset for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZkB6Lhlu7A4"
   },
   "outputs": [],
   "source": [
    "# ai = authors[authors.id == 2310124346].index[0]\n",
    "# term = \"query optimization\".capitalize()\n",
    "# authors.loc[ai, 'tags'] = authors.loc[ai, 'tags'].replace(\"]\", f\", {{'t': '{term}'}}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7dDnUm75qox"
   },
   "outputs": [],
   "source": [
    "# authors.loc[ai, 'tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Ou-ZYHXez0L"
   },
   "outputs": [],
   "source": [
    "# INTUITION:\n",
    "# Given a paper that has 4 authors and we choose the uniform strategy where each author gets 1/|authors| score of the paper\n",
    "# we then take author X, take all the scores achieved by the uniform strategy above, and calculate the expCombSUM over them.\n",
    "# This is then the end score for that author. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdOZj3YXZZ0d"
   },
   "outputs": [],
   "source": [
    "# Because of the way the index works with the depth of the search and the memory limitations, we retrieve all the papers that have\n",
    "# score higher than a threshold (let's say higher than 0.5) similarity to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CUpqdrK7bXhZ"
   },
   "outputs": [],
   "source": [
    "# Because my set is not THAT big, let's take top 100 papers instead of top 1000 or threshold based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NmmrcDAcHtZx"
   },
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'authors', 'venue', 'year', 'n_citation', 'page_start',\n",
       "       'page_end', 'doc_type', 'publisher', 'volume', 'issue', 'fos', 'doi',\n",
       "       'references', 'indexed_abstract', 'abstract',\n",
       "       'cleaned_abstract_sentences', 'cleaned_title', 'title_embedding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mLgMEr9-HwK9"
   },
   "outputs": [],
   "source": [
    "# Get the exact topic query evaluation for the 100 queries.\n",
    "exact = [get_author_ranking_exact_v2(query, index, tfidf=False, strategy=\"binary\", normalized=True, norm_alpha=1) for query in queries]\n",
    "\n",
    "# Get the approximate topic query evaluation for the 100 queries.\n",
    "approximate = [get_author_ranking_approximate_v2(query, index, tfidf=False, strategy=\"binary\", normalized=True, norm_alpha=1) for query in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the exact topic query evaluation for the 100 queries.\n",
    "exact_uniform = [get_author_ranking_exact_v2(query, index, tfidf=False, strategy=\"uniform\", normalized=True, norm_alpha=1) for query in queries]\n",
    "\n",
    "# Get the approximate topic query evaluation for the 100 queries.\n",
    "approximate_uniform = [get_author_ranking_approximate_v2(query, index, tfidf=False, strategy=\"uniform\", normalized=True, norm_alpha=1) for query in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact binary MRR@10: 0.619\n",
      "Approximate binary MRR@10: 0.678\n",
      "Exact binary MAP@10: 0.174\n",
      "Approximate binary MAP@10: 0.284\n",
      "Exact binary MP@10: 0.282\n",
      "Approximate binary MP@10: 0.42\n",
      "Exact binary MP@5: 0.272\n",
      "Approximate binary MP@5: 0.398\n",
      "---\n",
      "Exact uniform MRR@10: 0.572\n",
      "Approximate uniform MRR@10: 0.654\n",
      "Exact uniform MAP@10: 0.207\n",
      "Approximate uniform MAP@10: 0.32\n",
      "Exact uniform MP@10: 0.336\n",
      "Approximate uniform MP@10: 0.471\n",
      "Exact uniform MP@5: 0.292\n",
      "Approximate uniform MP@5: 0.422\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact binary MRR@10:\", mean_reciprocal_rank(exact))\n",
    "print(\"Approximate binary MRR@10:\", mean_reciprocal_rank(approximate))\n",
    "print(\"Exact binary MAP@10:\", mean_average_precision(exact))\n",
    "print(\"Approximate binary MAP@10:\", mean_average_precision(approximate))\n",
    "print(\"Exact binary MP@10:\", mean_precision_at_n(exact, 10))\n",
    "print(\"Approximate binary MP@10:\", mean_precision_at_n(approximate, 10))\n",
    "print(\"Exact binary MP@5:\", mean_precision_at_n(exact, 5))\n",
    "print(\"Approximate binary MP@5:\", mean_precision_at_n(approximate, 5))\n",
    "print(\"---\")\n",
    "print(\"Exact uniform MRR@10:\", mean_reciprocal_rank(exact_uniform))\n",
    "print(\"Approximate uniform MRR@10:\", mean_reciprocal_rank(approximate_uniform))\n",
    "print(\"Exact uniform MAP@10:\", mean_average_precision(exact_uniform))\n",
    "print(\"Approximate uniform MAP@10:\", mean_average_precision(approximate_uniform))\n",
    "print(\"Exact uniform MP@10:\", mean_precision_at_n(exact_uniform, 10))\n",
    "print(\"Approximate uniform MP@10:\", mean_precision_at_n(approximate_uniform, 10))\n",
    "print(\"Exact uniform MP@5:\", mean_precision_at_n(exact_uniform, 5))\n",
    "print(\"Approximate uniform MP@5:\", mean_precision_at_n(approximate_uniform, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the exact topic query evaluation for the 100 queries.\n",
    "exact_bigger_alpha = [get_author_ranking_exact_v2(query, index, tfidf=False, strategy=\"binary\", normalized=True, norm_alpha=1000) for query in queries]\n",
    "\n",
    "# Get the approximate topic query evaluation for the 100 queries.\n",
    "approximate_bigger_alpha = [get_author_ranking_approximate_v2(query, index, tfidf=False, strategy=\"binary\", normalized=True, norm_alpha=1000) for query in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact binary MRR@10: 0.694\n",
      "Approximate binary MRR@10: 0.737\n",
      "Exact binary MAP@10: 0.218\n",
      "Approximate binary MAP@10: 0.331\n",
      "Exact binary MP@10: 0.318\n",
      "Approximate binary MP@10: 0.452\n",
      "Exact binary MP@5: 0.324\n",
      "Approximate binary MP@5: 0.456\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact binary MRR@10:\", mean_reciprocal_rank(exact_bigger_alpha))\n",
    "print(\"Approximate binary MRR@10:\", mean_reciprocal_rank(approximate_bigger_alpha))\n",
    "print(\"Exact binary MAP@10:\", mean_average_precision(exact_bigger_alpha))\n",
    "print(\"Approximate binary MAP@10:\", mean_average_precision(approximate_bigger_alpha))\n",
    "print(\"Exact binary MP@10:\", mean_precision_at_n(exact_bigger_alpha, 10))\n",
    "print(\"Approximate binary MP@10:\", mean_precision_at_n(approximate_bigger_alpha, 10))\n",
    "print(\"Exact binary MP@5:\", mean_precision_at_n(exact_bigger_alpha, 5))\n",
    "print(\"Approximate binary MP@5:\", mean_precision_at_n(approximate_bigger_alpha, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the exact topic query evaluation for the 100 queries.\n",
    "exact_bigger_alpha_term = [get_author_ranking_exact_v2(query, index, tfidf=False, strategy=\"binary\", \n",
    "                                                       normalized=True, norm_alpha=1000, extra_term=50) for query in queries]\n",
    "\n",
    "# Get the approximate topic query evaluation for the 100 queries.\n",
    "approximate_bigger_alpha_term = [get_author_ranking_approximate_v2(query, index, tfidf=False, strategy=\"binary\", \n",
    "                                                                   normalized=True, norm_alpha=1000, extra_term=50) for query in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact binary MRR@10: 0.769\n",
      "Approximate binary MRR@10: 0.81\n",
      "Exact binary MAP@10: 0.362\n",
      "Approximate binary MAP@10: 0.49\n",
      "Exact binary MP@10: 0.455\n",
      "Approximate binary MP@10: 0.589\n",
      "Exact binary MP@5: 0.466\n",
      "Approximate binary MP@5: 0.602\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact binary MRR@10:\", mean_reciprocal_rank(exact_bigger_alpha_term))\n",
    "print(\"Approximate binary MRR@10:\", mean_reciprocal_rank(approximate_bigger_alpha_term))\n",
    "print(\"Exact binary MAP@10:\", mean_average_precision(exact_bigger_alpha_term))\n",
    "print(\"Approximate binary MAP@10:\", mean_average_precision(approximate_bigger_alpha_term))\n",
    "print(\"Exact binary MP@10:\", mean_precision_at_n(exact_bigger_alpha_term, 10))\n",
    "print(\"Approximate binary MP@10:\", mean_precision_at_n(approximate_bigger_alpha_term, 10))\n",
    "print(\"Exact binary MP@5:\", mean_precision_at_n(exact_bigger_alpha_term, 5))\n",
    "print(\"Approximate binary MP@5:\", mean_precision_at_n(approximate_bigger_alpha_term, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the exact topic query evaluation for the 100 queries.\n",
    "exact_bigger_alpha_term = [get_author_ranking_exact_v2(query, index, tfidf=False, strategy=\"binary\", \n",
    "                                                       normalized=True, norm_alpha=1000, extra_term=100) for query in queries]\n",
    "\n",
    "# Get the approximate topic query evaluation for the 100 queries.\n",
    "approximate_bigger_alpha_term = [get_author_ranking_approximate_v2(query, index, tfidf=False, strategy=\"binary\", \n",
    "                                                                   normalized=True, norm_alpha=1000, extra_term=100) for query in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact binary MRR@10: 0.813\n",
      "Approximate binary MRR@10: 0.853\n",
      "Exact binary MAP@10: 0.404\n",
      "Approximate binary MAP@10: 0.548\n",
      "Exact binary MP@10: 0.491\n",
      "Approximate binary MP@10: 0.638\n",
      "Exact binary MP@5: 0.52\n",
      "Approximate binary MP@5: 0.658\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact binary MRR@10:\", mean_reciprocal_rank(exact_bigger_alpha_term))\n",
    "print(\"Approximate binary MRR@10:\", mean_reciprocal_rank(approximate_bigger_alpha_term))\n",
    "print(\"Exact binary MAP@10:\", mean_average_precision(exact_bigger_alpha_term))\n",
    "print(\"Approximate binary MAP@10:\", mean_average_precision(approximate_bigger_alpha_term))\n",
    "print(\"Exact binary MP@10:\", mean_precision_at_n(exact_bigger_alpha_term, 10))\n",
    "print(\"Approximate binary MP@10:\", mean_precision_at_n(approximate_bigger_alpha_term, 10))\n",
    "print(\"Exact binary MP@5:\", mean_precision_at_n(exact_bigger_alpha_term, 5))\n",
    "print(\"Approximate binary MP@5:\", mean_precision_at_n(approximate_bigger_alpha_term, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the exact topic query evaluation for the 100 queries.\n",
    "exact_bigger_alpha_term = [get_author_ranking_exact_v2(query, index, tfidf=False, strategy=\"binary\", \n",
    "                                                       normalized=True, norm_alpha=100, extra_term=100) for query in queries]\n",
    "\n",
    "# Get the approximate topic query evaluation for the 100 queries.\n",
    "approximate_bigger_alpha_term = [get_author_ranking_approximate_v2(query, index, tfidf=False, strategy=\"binary\", \n",
    "                                                                   normalized=True, norm_alpha=100, extra_term=100) for query in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact binary MRR@10: 0.787\n",
      "Approximate binary MRR@10: 0.838\n",
      "Exact binary MAP@10: 0.403\n",
      "Approximate binary MAP@10: 0.542\n",
      "Exact binary MP@10: 0.492\n",
      "Approximate binary MP@10: 0.634\n",
      "Exact binary MP@5: 0.512\n",
      "Approximate binary MP@5: 0.65\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact binary MRR@10:\", mean_reciprocal_rank(exact_bigger_alpha_term))\n",
    "print(\"Approximate binary MRR@10:\", mean_reciprocal_rank(approximate_bigger_alpha_term))\n",
    "print(\"Exact binary MAP@10:\", mean_average_precision(exact_bigger_alpha_term))\n",
    "print(\"Approximate binary MAP@10:\", mean_average_precision(approximate_bigger_alpha_term))\n",
    "print(\"Exact binary MP@10:\", mean_precision_at_n(exact_bigger_alpha_term, 10))\n",
    "print(\"Approximate binary MP@10:\", mean_precision_at_n(approximate_bigger_alpha_term, 10))\n",
    "print(\"Exact binary MP@5:\", mean_precision_at_n(exact_bigger_alpha_term, 5))\n",
    "print(\"Approximate binary MP@5:\", mean_precision_at_n(approximate_bigger_alpha_term, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fd5nks9gIDXl"
   },
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(results):\n",
    "    partial_ranks = []\n",
    "    \n",
    "    for result in results:\n",
    "        sortd = sorted(result.items(), key=lambda item: item[1]['rank'])\n",
    "\n",
    "        for s in sortd:\n",
    "            if s[1]['relevancy'] == True:\n",
    "                # We had to do rank from 1 on instead of 0 on because of the 1 / rank formula.\n",
    "                partial_ranks.append(1 / (s[1]['rank']+1))\n",
    "                break\n",
    "    \n",
    "    mrr = np.around(np.mean(partial_ranks), decimals=3)\n",
    "    \n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9YS5zj6nK_Bq",
    "outputId": "bcf27f79-83d5-4bcf-98ce-63159e637c10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reciprocal_rank(approximate_parabolic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XAAUsbJfvYZ"
   },
   "outputs": [],
   "source": [
    "def mean_average_precision(results):\n",
    "    \n",
    "    average_precision_scores = []\n",
    "    \n",
    "    for result in results:\n",
    "        sortd = sorted(result.items(), key=lambda item: item[1]['rank'])\n",
    "        \n",
    "        average_precison_partials_list = []\n",
    "        current_sublist_size = 0\n",
    "        relevant_found = 0\n",
    "        \n",
    "        for s in sortd:\n",
    "            if s[1]['relevancy'] == True:\n",
    "                current_sublist_size += 1\n",
    "                relevant_found += 1\n",
    "                average_precision_partial = relevant_found / current_sublist_size\n",
    "                average_precison_partials_list.append(average_precision_partial)\n",
    "            else:\n",
    "                current_sublist_size += 1\n",
    "\n",
    "        average_precision = np.sum(average_precison_partials_list) / len(sortd)\n",
    "        average_precision_scores.append(average_precision)\n",
    "    \n",
    "    mapr = np.around(np.mean(average_precision_scores), decimals=3)\n",
    "    \n",
    "    return mapr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QHg1Q6Rdy7yL",
    "outputId": "e9cdf8e8-bec3-41c4-bbfe-03da6e23bd29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.486"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision(exact_parabolic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yziOQ-xIRFfU"
   },
   "outputs": [],
   "source": [
    "def mean_precision_at_n(results, n=5):\n",
    "    \n",
    "    average_precision_scores = []\n",
    "    \n",
    "    for result in results:\n",
    "        \n",
    "        sortd = sorted(result.items(), key=lambda item: item[1]['rank'])\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        for s in sortd[:n]:\n",
    "            if s[1]['relevancy'] == True:\n",
    "                correct += 1\n",
    "        \n",
    "        average_precision_scores.append(correct / n)\n",
    "    \n",
    "    mpan = np.around(np.mean(average_precision_scores), decimals=3)\n",
    "    \n",
    "    return mpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NrnLftVHVLnb",
    "outputId": "f08940a9-e4b4-4a78-aefd-63db6e9098f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.565"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_precision_at_n(exact_parabolic, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v2QY6ec8IMzN"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_exact_to_pickle(name):\n",
    "    path = f'exact_evaluation_{name}.pickle'\n",
    "    print(\"exact path:\", path)\n",
    "    with open(path, 'wb') as handle:\n",
    "        pickle.dump(exact, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def save_approximate_to_pickle(name):\n",
    "    path = f'approximate_evaluation_07thresh_{name}.pickle'\n",
    "    print(\"Approximate path:\", path)\n",
    "    with open(path, 'wb') as handle:\n",
    "        pickle.dump(approximate, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "u9VCD_AaLdy6",
    "outputId": "469cf6f9-7fe9-48b3-ff21-e9656bcd6e34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact path: exact_evaluation_average_separate_sbert.pickle\n",
      "Approximate path: approximate_evaluation_07thresh_average_separate_sbert.pickle\n"
     ]
    }
   ],
   "source": [
    "current = \"average_separate_sbert\"\n",
    "save_exact_to_pickle(current)\n",
    "save_approximate_to_pickle(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "jI6i18arLjTQ",
    "outputId": "8763e795-4faf-43f8-d0a1-5ff53e885a8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1686244749: {'rank': 2, 'relevancy': True},\n",
       " 2087992123: {'rank': 6, 'relevancy': True},\n",
       " 2120281063: {'rank': 1, 'relevancy': True},\n",
       " 2122589528: {'rank': 7, 'relevancy': False},\n",
       " 2136847405: {'rank': 0, 'relevancy': True},\n",
       " 2142158874: {'rank': 4, 'relevancy': True},\n",
       " 2169261213: {'rank': 3, 'relevancy': True},\n",
       " 2255627707: {'rank': 8, 'relevancy': True},\n",
       " 2310891340: {'rank': 9, 'relevancy': False},\n",
       " 2473457260: {'rank': 5, 'relevancy': True}}"
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "qJGA09sGZ5xF",
    "outputId": "a9259c90-a2a0-4560-9dd0-28ecdd904abe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1670727492: {'rank': 7, 'relevancy': False},\n",
       " 1862709724: {'rank': 0, 'relevancy': False},\n",
       " 1983671951: {'rank': 1, 'relevancy': False},\n",
       " 2057144527: {'rank': 4, 'relevancy': False},\n",
       " 2170785820: {'rank': 6, 'relevancy': False},\n",
       " 2250996746: {'rank': 9, 'relevancy': False},\n",
       " 2253241183: {'rank': 2, 'relevancy': False},\n",
       " 2461703321: {'rank': 3, 'relevancy': False},\n",
       " 2574610794: {'rank': 5, 'relevancy': False},\n",
       " 2577966764: {'rank': 8, 'relevancy': False}}"
      ]
     },
     "execution_count": 147,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact[73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZK3c_wdJZ8ES",
    "outputId": "c0e79e6d-05d6-4e93-cf53-c4b4fff34ee9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Novelty detection'"
      ]
     },
     "execution_count": 148,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bauGhGv8QT6q"
   },
   "outputs": [],
   "source": [
    "# ai = authors[authors.id == 2325036826].index[0]\n",
    "# term = query.capitalize()\n",
    "# authors.loc[ai, 'tags'] = authors.loc[ai, 'tags'].replace(\"]\", f\", {{'t': '{term}'}}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "N04EGqHYZ9ZP",
    "outputId": "fb22bf1a-f40d-418a-da67-44f539c32d68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1151530292': {'rank': 3, 'relevancy': False},\n",
       " '2004366870': {'rank': 5, 'relevancy': True},\n",
       " '2130711152': {'rank': 4, 'relevancy': True},\n",
       " '2135488253': {'rank': 0, 'relevancy': True},\n",
       " '2616859289': {'rank': 2, 'relevancy': True},\n",
       " '374805745': {'rank': 7, 'relevancy': False},\n",
       " '56197593': {'rank': 6, 'relevancy': True},\n",
       " '798588419': {'rank': 1, 'relevancy': False}}"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact[67]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IHkv8xZ8eQWu"
   },
   "source": [
    "## Code for the non-binary evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>n_pubs</th>\n",
       "      <th>name</th>\n",
       "      <th>pubs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100167829</td>\n",
       "      <td>1184</td>\n",
       "      <td>117</td>\n",
       "      <td>Fabio Massimo Zanzotto</td>\n",
       "      <td>[{'i': '371408518', 'r': 2}, {'i': '1487779154...</td>\n",
       "      <td>[{'t': 'Semantic data model'}, {'t': 'Cancer'}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100252078</td>\n",
       "      <td>1042</td>\n",
       "      <td>131</td>\n",
       "      <td>Stefano Serra-Capizzano</td>\n",
       "      <td>[{'i': '2132492255', 'r': 1}, {'i': '252184247...</td>\n",
       "      <td>[{'t': 'Spectral power distribution'}, {'t': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100748767</td>\n",
       "      <td>1689</td>\n",
       "      <td>149</td>\n",
       "      <td>Christian Goerick</td>\n",
       "      <td>[{'i': '44505', 'r': 3}, {'i': '2132496341', '...</td>\n",
       "      <td>[{'t': 'Operating system'}, {'t': 'Homeostasis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100988613</td>\n",
       "      <td>2312</td>\n",
       "      <td>248</td>\n",
       "      <td>Eiichiro Sumita</td>\n",
       "      <td>[{'i': '2132594454', 'r': 1}, {'i': '199925832...</td>\n",
       "      <td>[{'t': 'Data quality'}, {'t': 'Principle of ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1013389924</td>\n",
       "      <td>5522</td>\n",
       "      <td>228</td>\n",
       "      <td>Pavol Hell</td>\n",
       "      <td>[{'i': '2410734113', 'r': 0}, {'i': '199932317...</td>\n",
       "      <td>[{'t': 'Hamiltonian path'}, {'t': 'Binary tree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67751</th>\n",
       "      <td>286732139</td>\n",
       "      <td>6104</td>\n",
       "      <td>164</td>\n",
       "      <td>Gadiel Seroussi</td>\n",
       "      <td>[{'i': '2229475340', 'r': 5}, {'i': '148955953...</td>\n",
       "      <td>[{'t': 'Geometric distribution'}, {'t': 'Codin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67761</th>\n",
       "      <td>286913512</td>\n",
       "      <td>8146</td>\n",
       "      <td>162</td>\n",
       "      <td>Javier R. Movellan</td>\n",
       "      <td>[{'i': '2133107415', 'r': 2}, {'i': '8203773',...</td>\n",
       "      <td>[{'t': 'Vision'}, {'t': 'Probability density f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67763</th>\n",
       "      <td>286952618</td>\n",
       "      <td>3978</td>\n",
       "      <td>384</td>\n",
       "      <td>Cecilia Laschi</td>\n",
       "      <td>[{'i': '2320062248', 'r': 2}, {'i': '213270181...</td>\n",
       "      <td>[{'t': 'Artificial muscle'}, {'t': 'Electroenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67782</th>\n",
       "      <td>287405489</td>\n",
       "      <td>9166</td>\n",
       "      <td>670</td>\n",
       "      <td>Peter Willett</td>\n",
       "      <td>[{'i': '1487494573', 'r': 1}, {'i': '213249600...</td>\n",
       "      <td>[{'t': 'Uncertainty principle'}, {'t': 'Linear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67794</th>\n",
       "      <td>287560032</td>\n",
       "      <td>7218</td>\n",
       "      <td>187</td>\n",
       "      <td>David V. Budescu</td>\n",
       "      <td>[{'i': '2132445536', 'r': 1}, {'i': '203893720...</td>\n",
       "      <td>[{'t': 'Framing'}, {'t': 'Uniform distribution...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11681 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  n_citation  n_pubs                     name  \\\n",
       "3       100167829        1184     117   Fabio Massimo Zanzotto   \n",
       "4       100252078        1042     131  Stefano Serra-Capizzano   \n",
       "19      100748767        1689     149        Christian Goerick   \n",
       "23      100988613        2312     248          Eiichiro Sumita   \n",
       "28     1013389924        5522     228               Pavol Hell   \n",
       "...           ...         ...     ...                      ...   \n",
       "67751   286732139        6104     164          Gadiel Seroussi   \n",
       "67761   286913512        8146     162       Javier R. Movellan   \n",
       "67763   286952618        3978     384           Cecilia Laschi   \n",
       "67782   287405489        9166     670            Peter Willett   \n",
       "67794   287560032        7218     187         David V. Budescu   \n",
       "\n",
       "                                                    pubs  \\\n",
       "3      [{'i': '371408518', 'r': 2}, {'i': '1487779154...   \n",
       "4      [{'i': '2132492255', 'r': 1}, {'i': '252184247...   \n",
       "19     [{'i': '44505', 'r': 3}, {'i': '2132496341', '...   \n",
       "23     [{'i': '2132594454', 'r': 1}, {'i': '199925832...   \n",
       "28     [{'i': '2410734113', 'r': 0}, {'i': '199932317...   \n",
       "...                                                  ...   \n",
       "67751  [{'i': '2229475340', 'r': 5}, {'i': '148955953...   \n",
       "67761  [{'i': '2133107415', 'r': 2}, {'i': '8203773',...   \n",
       "67763  [{'i': '2320062248', 'r': 2}, {'i': '213270181...   \n",
       "67782  [{'i': '1487494573', 'r': 1}, {'i': '213249600...   \n",
       "67794  [{'i': '2132445536', 'r': 1}, {'i': '203893720...   \n",
       "\n",
       "                                                    tags  \n",
       "3      [{'t': 'Semantic data model'}, {'t': 'Cancer'}...  \n",
       "4      [{'t': 'Spectral power distribution'}, {'t': '...  \n",
       "19     [{'t': 'Operating system'}, {'t': 'Homeostasis...  \n",
       "23     [{'t': 'Data quality'}, {'t': 'Principle of ma...  \n",
       "28     [{'t': 'Hamiltonian path'}, {'t': 'Binary tree...  \n",
       "...                                                  ...  \n",
       "67751  [{'t': 'Geometric distribution'}, {'t': 'Codin...  \n",
       "67761  [{'t': 'Vision'}, {'t': 'Probability density f...  \n",
       "67763  [{'t': 'Artificial muscle'}, {'t': 'Electroenc...  \n",
       "67782  [{'t': 'Uncertainty principle'}, {'t': 'Linear...  \n",
       "67794  [{'t': 'Framing'}, {'t': 'Uniform distribution...  \n",
       "\n",
       "[11681 rows x 6 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors[authors.n_pubs > 100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pubs_by_author_id(author_id):\n",
    "    pubs = ast.literal_eval(authors[authors.id == author_id].pubs.values[0])\n",
    "    return [p[\"i\"] for p in pubs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tag_frequencies(author_id):\n",
    "    pubs = get_pubs_by_author_id(author_id)\n",
    "    all_fos = []\n",
    "    for p in pubs:\n",
    "        try:\n",
    "            fos = [f[\"name\"] for f in get_fos_by_id(p)]\n",
    "            all_fos.extend(fos)\n",
    "        except:\n",
    "            continue\n",
    "    return Counter(all_fos).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mathematics', 13),\n",
       " ('Statistics', 12),\n",
       " ('Econometrics', 10),\n",
       " ('Feature selection', 7),\n",
       " ('Model selection', 6),\n",
       " ('Artificial intelligence', 5),\n",
       " ('Bayesian linear regression', 4),\n",
       " ('Pattern recognition', 4),\n",
       " ('Linear regression', 4),\n",
       " ('Markov chain Monte Carlo', 4),\n",
       " ('g-prior', 3),\n",
       " (\"Bayes' theorem\", 3),\n",
       " ('Nonparametric regression', 3),\n",
       " ('Posterior probability', 3),\n",
       " ('Boosting (machine learning)', 3),\n",
       " ('Ensemble learning', 3),\n",
       " ('Machine learning', 3),\n",
       " ('Statistical model', 3),\n",
       " ('Prior probability', 3),\n",
       " ('Computer science', 3),\n",
       " ('Hyperparameter', 2),\n",
       " ('Marginal likelihood', 2),\n",
       " ('Bayes factor', 2),\n",
       " ('Bayesian hierarchical modeling', 2),\n",
       " ('Mixture model', 2),\n",
       " ('Gibbs sampling', 2),\n",
       " ('Bayesian probability', 2),\n",
       " ('Bayes estimator', 2),\n",
       " ('Minimax', 2),\n",
       " ('Monte Carlo method', 2),\n",
       " (\"Bayes' rule\", 1),\n",
       " ('Shrinkage estimator', 1),\n",
       " ('Naive Bayes classifier', 1),\n",
       " ('Bayes error rate', 1),\n",
       " ('Latent variable', 1),\n",
       " ('Multinomial distribution', 1),\n",
       " ('Gradient boosting', 1),\n",
       " ('Random forest', 1),\n",
       " ('Covariate', 1),\n",
       " ('Expectationmaximization algorithm', 1),\n",
       " ('Search algorithm', 1),\n",
       " ('Emulation', 1),\n",
       " ('Bias of an estimator', 1),\n",
       " ('Multivariate analysis', 1),\n",
       " ('A priori and a posteriori', 1),\n",
       " ('Shrinkage', 1),\n",
       " ('Multivariate normal distribution', 1),\n",
       " ('Explained sum of squares', 1),\n",
       " ('Residual sum of squares', 1),\n",
       " ('Inference', 1),\n",
       " ('Decision theory', 1),\n",
       " ('Risk analysis (business)', 1),\n",
       " ('Curse of dimensionality', 1),\n",
       " ('Binary logarithm', 1),\n",
       " ('Inverse-chi-squared distribution', 1),\n",
       " ('Bayesian statistics', 1),\n",
       " ('Data science', 1),\n",
       " ('Variable-order Bayesian network', 1),\n",
       " ('Bayesian average', 1),\n",
       " ('Categorical distribution', 1),\n",
       " ('Monte Carlo algorithm', 1),\n",
       " ('Rejection sampling', 1),\n",
       " ('Algorithm', 1),\n",
       " ('Monte Carlo integration', 1),\n",
       " ('Quasi-Monte Carlo method', 1),\n",
       " ('Theoretical computer science', 1),\n",
       " ('Particle filter', 1),\n",
       " ('Hybrid Monte Carlo', 1),\n",
       " ('Marginal distribution', 1),\n",
       " ('Conditional probability distribution', 1),\n",
       " ('Markov chain', 1),\n",
       " ('Resampling', 1),\n",
       " ('Outlier', 1),\n",
       " ('Estimator', 1),\n",
       " ('Wavelet', 1),\n",
       " ('Bayesian inference', 1),\n",
       " ('Parametric statistics', 1),\n",
       " ('Parametric model', 1),\n",
       " ('Cross-validation', 1),\n",
       " ('Binary tree', 1),\n",
       " ('Data set', 1),\n",
       " ('Probit model', 1),\n",
       " ('Interval estimation', 1)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_tag_frequencies(2347934206)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'183722240': {'relevancy': True, 'rank': 0},\n",
       " '2149454608': {'relevancy': True, 'rank': 1},\n",
       " '2347934206': {'relevancy': True, 'rank': 2},\n",
       " '2056153991': {'relevancy': True, 'rank': 3},\n",
       " '2435751034': {'relevancy': True, 'rank': 4},\n",
       " '2123777986': {'relevancy': False, 'rank': 5},\n",
       " '1964890520': {'relevancy': False, 'rank': 6},\n",
       " '2635064073': {'relevancy': True, 'rank': 7},\n",
       " '2131550435': {'relevancy': True, 'rank': 8},\n",
       " '2304614720': {'relevancy': True, 'rank': 9}}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_norm_semantic_role_labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>page_start</th>\n",
       "      <th>page_end</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>publisher</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>fos</th>\n",
       "      <th>doi</th>\n",
       "      <th>references</th>\n",
       "      <th>indexed_abstract</th>\n",
       "      <th>abstract</th>\n",
       "      <th>cleaned_abstract_sentences</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>title_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13738</th>\n",
       "      <td>2293576742</td>\n",
       "      <td>Hierarchical Penalization</td>\n",
       "      <td>[{'name': 'Marie Szafranski', 'id': '208893902...</td>\n",
       "      <td>{'raw': 'neural information processing systems...</td>\n",
       "      <td>2007</td>\n",
       "      <td>20</td>\n",
       "      <td>1457</td>\n",
       "      <td>1464</td>\n",
       "      <td>Conference</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'name': 'Mathematical optimization', 'w': 0....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1984568490, 2063978378, 2084812512, 211336235...</td>\n",
       "      <td>{'IndexLength': 95, 'InvertedIndex': {'Hierarc...</td>\n",
       "      <td>Hierarchical penalization is a generic framewo...</td>\n",
       "      <td>[hierarchical penalization is generic framewor...</td>\n",
       "      <td>hierarchical penalization</td>\n",
       "      <td>[0.33533376, 0.87247276, 0.76960266, -0.684895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49743</th>\n",
       "      <td>2109001758</td>\n",
       "      <td>Rotation invariant pattern recognition using r...</td>\n",
       "      <td>[{'name': 'Guangyi Chen', 'id': '2097743728', ...</td>\n",
       "      <td>{'raw': 'Pattern Recognition', 'id': '414566'}</td>\n",
       "      <td>2005</td>\n",
       "      <td>45</td>\n",
       "      <td>2314</td>\n",
       "      <td>2322</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Elsevier Science Inc.</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>[{'name': 'Gravitational singularity', 'w': 0....</td>\n",
       "      <td>10.1016/j.patcog.2005.02.008</td>\n",
       "      <td>[58440828, 1523039621, 1535724155, 1912117388,...</td>\n",
       "      <td>{'IndexLength': 146, 'InvertedIndex': {'In': [...</td>\n",
       "      <td>In this paper, we propose a rotation-invariant...</td>\n",
       "      <td>[in this paper propose rotation invariant desc...</td>\n",
       "      <td>rotation invariant pattern recognition using r...</td>\n",
       "      <td>[0.46960822, -0.26783612, 0.07540989, 1.084667...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80387</th>\n",
       "      <td>2056282082</td>\n",
       "      <td>Wavelet-based fingerprint image retrieval</td>\n",
       "      <td>[{'name': 'Javier A. Montoya Zegarra', 'id': '...</td>\n",
       "      <td>{'raw': 'Journal of Computational and Applied ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>26</td>\n",
       "      <td>294</td>\n",
       "      <td>307</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Elsevier Science Publishers B. V.</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'name': 'Feature vector', 'w': 0.5480565}, {...</td>\n",
       "      <td>10.1016/j.cam.2008.03.017</td>\n",
       "      <td>[5057334, 23094940, 1497286775, 1501535725, 15...</td>\n",
       "      <td>{'IndexLength': 193, 'InvertedIndex': {'This':...</td>\n",
       "      <td>This paper presents a novel approach for perso...</td>\n",
       "      <td>[this paper presents novel approach for person...</td>\n",
       "      <td>wavelet based fingerprint image retrieval</td>\n",
       "      <td>[0.664778, -0.8043635, 0.706223, -0.1874655, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101477</th>\n",
       "      <td>1913131897</td>\n",
       "      <td>A monotonic and continuous two-dimensional war...</td>\n",
       "      <td>[{'name': 'Seiichi Uchida', 'id': '2119334787'...</td>\n",
       "      <td>{'raw': 'international conference on pattern r...</td>\n",
       "      <td>1998</td>\n",
       "      <td>53</td>\n",
       "      <td>521</td>\n",
       "      <td>524</td>\n",
       "      <td>Conference</td>\n",
       "      <td>IEEE Computer Society</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>[{'name': 'Monotonic function', 'w': 0.4788851...</td>\n",
       "      <td>10.1109/ICPR.1998.711195</td>\n",
       "      <td>[1965509304, 2006952799, 2144789800, 215413730...</td>\n",
       "      <td>{'IndexLength': 67, 'InvertedIndex': {'A': [0]...</td>\n",
       "      <td>A two-dimensional warping algorithm is present...</td>\n",
       "      <td>[two dimensional warping algorithm is presente...</td>\n",
       "      <td>monotonic and continuous two dimensional warpi...</td>\n",
       "      <td>[0.08126288, 0.42223737, -0.20103915, 0.409545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95922</th>\n",
       "      <td>2064167155</td>\n",
       "      <td>Model comparison of nonlinear structural equat...</td>\n",
       "      <td>[{'name': 'Sik-Yum Lee', 'id': '2141248418', '...</td>\n",
       "      <td>{'raw': 'Psychometrika', 'id': '186480540'}</td>\n",
       "      <td>2003</td>\n",
       "      <td>51</td>\n",
       "      <td>27</td>\n",
       "      <td>47</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Springer</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'name': 'Latent variable', 'w': 0.5037348}, ...</td>\n",
       "      <td>10.1007/BF02296651</td>\n",
       "      <td>[133598609, 147337607, 1494853941, 1747608905,...</td>\n",
       "      <td>{'IndexLength': 127, 'InvertedIndex': {'Recent...</td>\n",
       "      <td>Recently, it has been recognized that the comm...</td>\n",
       "      <td>[recently has been recognized that the commonl...</td>\n",
       "      <td>model comparison of nonlinear structural equat...</td>\n",
       "      <td>[0.5628841, -0.13408846, -0.05693955, 1.312504...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                              title  \\\n",
       "13738   2293576742                          Hierarchical Penalization   \n",
       "49743   2109001758  Rotation invariant pattern recognition using r...   \n",
       "80387   2056282082          Wavelet-based fingerprint image retrieval   \n",
       "101477  1913131897  A monotonic and continuous two-dimensional war...   \n",
       "95922   2064167155  Model comparison of nonlinear structural equat...   \n",
       "\n",
       "                                                  authors  \\\n",
       "13738   [{'name': 'Marie Szafranski', 'id': '208893902...   \n",
       "49743   [{'name': 'Guangyi Chen', 'id': '2097743728', ...   \n",
       "80387   [{'name': 'Javier A. Montoya Zegarra', 'id': '...   \n",
       "101477  [{'name': 'Seiichi Uchida', 'id': '2119334787'...   \n",
       "95922   [{'name': 'Sik-Yum Lee', 'id': '2141248418', '...   \n",
       "\n",
       "                                                    venue  year  n_citation  \\\n",
       "13738   {'raw': 'neural information processing systems...  2007          20   \n",
       "49743      {'raw': 'Pattern Recognition', 'id': '414566'}  2005          45   \n",
       "80387   {'raw': 'Journal of Computational and Applied ...  2009          26   \n",
       "101477  {'raw': 'international conference on pattern r...  1998          53   \n",
       "95922         {'raw': 'Psychometrika', 'id': '186480540'}  2003          51   \n",
       "\n",
       "       page_start page_end    doc_type                          publisher  \\\n",
       "13738        1457     1464  Conference                                      \n",
       "49743        2314     2322     Journal              Elsevier Science Inc.   \n",
       "80387         294      307     Journal  Elsevier Science Publishers B. V.   \n",
       "101477        521      524  Conference              IEEE Computer Society   \n",
       "95922          27       47     Journal                           Springer   \n",
       "\n",
       "       volume issue                                                fos  \\\n",
       "13738                [{'name': 'Mathematical optimization', 'w': 0....   \n",
       "49743      38    12  [{'name': 'Gravitational singularity', 'w': 0....   \n",
       "80387     227     2  [{'name': 'Feature vector', 'w': 0.5480565}, {...   \n",
       "101477      1        [{'name': 'Monotonic function', 'w': 0.4788851...   \n",
       "95922      68     1  [{'name': 'Latent variable', 'w': 0.5037348}, ...   \n",
       "\n",
       "                                 doi  \\\n",
       "13738                            NaN   \n",
       "49743   10.1016/j.patcog.2005.02.008   \n",
       "80387      10.1016/j.cam.2008.03.017   \n",
       "101477      10.1109/ICPR.1998.711195   \n",
       "95922             10.1007/BF02296651   \n",
       "\n",
       "                                               references  \\\n",
       "13738   [1984568490, 2063978378, 2084812512, 211336235...   \n",
       "49743   [58440828, 1523039621, 1535724155, 1912117388,...   \n",
       "80387   [5057334, 23094940, 1497286775, 1501535725, 15...   \n",
       "101477  [1965509304, 2006952799, 2144789800, 215413730...   \n",
       "95922   [133598609, 147337607, 1494853941, 1747608905,...   \n",
       "\n",
       "                                         indexed_abstract  \\\n",
       "13738   {'IndexLength': 95, 'InvertedIndex': {'Hierarc...   \n",
       "49743   {'IndexLength': 146, 'InvertedIndex': {'In': [...   \n",
       "80387   {'IndexLength': 193, 'InvertedIndex': {'This':...   \n",
       "101477  {'IndexLength': 67, 'InvertedIndex': {'A': [0]...   \n",
       "95922   {'IndexLength': 127, 'InvertedIndex': {'Recent...   \n",
       "\n",
       "                                                 abstract  \\\n",
       "13738   Hierarchical penalization is a generic framewo...   \n",
       "49743   In this paper, we propose a rotation-invariant...   \n",
       "80387   This paper presents a novel approach for perso...   \n",
       "101477  A two-dimensional warping algorithm is present...   \n",
       "95922   Recently, it has been recognized that the comm...   \n",
       "\n",
       "                               cleaned_abstract_sentences  \\\n",
       "13738   [hierarchical penalization is generic framewor...   \n",
       "49743   [in this paper propose rotation invariant desc...   \n",
       "80387   [this paper presents novel approach for person...   \n",
       "101477  [two dimensional warping algorithm is presente...   \n",
       "95922   [recently has been recognized that the commonl...   \n",
       "\n",
       "                                            cleaned_title  \\\n",
       "13738                           hierarchical penalization   \n",
       "49743   rotation invariant pattern recognition using r...   \n",
       "80387           wavelet based fingerprint image retrieval   \n",
       "101477  monotonic and continuous two dimensional warpi...   \n",
       "95922   model comparison of nonlinear structural equat...   \n",
       "\n",
       "                                          title_embedding  \n",
       "13738   [0.33533376, 0.87247276, 0.76960266, -0.684895...  \n",
       "49743   [0.46960822, -0.26783612, 0.07540989, 1.084667...  \n",
       "80387   [0.664778, -0.8043635, 0.706223, -0.1874655, -...  \n",
       "101477  [0.08126288, 0.42223737, -0.20103915, 0.409545...  \n",
       "95922   [0.5628841, -0.13408846, -0.05693955, 1.312504...  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [('World Wide Web', 1),\n",
    " ('World Wide Web', 1),\n",
    " ('World Wide Web', 1),\n",
    " ('Social web', 7),\n",
    " ('World Wide Web', 7),\n",
    " ('World Wide Web', 9),\n",
    " ('Social web', 9),\n",
    " ('World Wide Web', 566),\n",
    " ('World Wide Web', 120),\n",
    " ('World Wide Web', 1),\n",
    " ('Semantic Web', 1),\n",
    " ('Semantic Web', 1),\n",
    " ('Semantic Web', 354),\n",
    " ('World Wide Web', 354),\n",
    " ('World Wide Web', 1),\n",
    " ('World Wide Web', 62),\n",
    " ('World Wide Web', 27),\n",
    " ('Ontology language', 27),\n",
    " ('World Wide Web', 46),\n",
    " ('Semantic Web', 46),\n",
    " ('OWL-S', 2),\n",
    " ('Semantic Web', 2),\n",
    " ('World Wide Web', 2),\n",
    " ('World Wide Web', 3),\n",
    " ('Semantic Web', 3),\n",
    " ('World Wide Web', 5),\n",
    " ('World Wide Web', 57),\n",
    " ('Semantic Web', 57),\n",
    " ('World Wide Web', 3),\n",
    " ('OWL-S', 3),\n",
    " ('World Wide Web', 3),\n",
    " ('Semantic Web', 3),\n",
    " ('World Wide Web', 6),\n",
    " ('Semantic grid', 6),\n",
    " ('Semantic Web', 6),\n",
    " ('World Wide Web', 3),\n",
    " ('Semantic Web', 23),\n",
    " ('Semantic grid', 23),\n",
    " ('World Wide Web', 37),\n",
    " ('World Wide Web', 47),\n",
    " ('Semantic Web', 47)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_tag_score(one_author):\n",
    "    tags_with_score = {}\n",
    "    for t in one_author:\n",
    "        tag = t[0]\n",
    "        cit = t[1]\n",
    "        if tag in tags_with_score:\n",
    "            tags_with_score[tag] += cit\n",
    "        else:\n",
    "            tags_with_score[tag] = cit\n",
    "    return tags_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OWL-S': 5,\n",
       " 'Ontology language': 27,\n",
       " 'Semantic Web': 543,\n",
       " 'Semantic grid': 29,\n",
       " 'Social web': 16,\n",
       " 'World Wide Web': 1362}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_tag_score(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1 = {'Semantic Web': 6833,\n",
    " 'World Wide Web': 17360,\n",
    " 'Semantic grid': 64,\n",
    " 'Logic programming': 44,\n",
    " 'Constraint satisfaction': 44,\n",
    " 'User interface': 17,\n",
    " 'Web service': 1424,\n",
    " 'Social web': 884,\n",
    " 'Web 2.0': 2069,\n",
    " 'Information privacy': 89,\n",
    " 'Social network': 84,\n",
    " 'Computer architecture': 1,\n",
    " 'Middleware': 676,\n",
    " 'Multi-agent system': 1263,\n",
    " 'Knowledge extraction': 4,\n",
    " 'Semantic similarity': 1,\n",
    " 'Ontology language': 27,\n",
    " 'OWL-S': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist2 = {'Dimensionality reduction': 2,\n",
    " 'Cluster analysis': 74,\n",
    " 'Hierarchical clustering': 24,\n",
    " 'Speech processing': 5,\n",
    " 'Image segmentation': 49,\n",
    " 'Medical imaging': 97,\n",
    " 'Wavelet transform': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist3 = {'Image segmentation': 75, 'Random forest': 14}\n",
    "dist4 = {'Topic model': 4,\n",
    " 'Genetic algorithm': 1,\n",
    " 'Cluster analysis': 3,\n",
    " 'Multi-task learning': 7,\n",
    " 'World Wide Web': 1}\n",
    "dist5 = {'Rule induction': 1078,\n",
    " 'User interface': 7,\n",
    " 'Game theory': 1,\n",
    " 'World Wide Web': 1,\n",
    " 'Web 2.0': 1}\n",
    "dist6 = {'Game theory': 1480, 'Eye tracking': 194}\n",
    "dist7 = {'Wearable computer': 22,\n",
    " 'Eye tracking': 38,\n",
    " 'Wireless sensor network': 1,\n",
    " 'Support vector machine': 2,\n",
    " 'Dynamic programming': 76}\n",
    "dist8 = {'User interface': 10}\n",
    "dist9 = {'Image segmentation': 130, 'Random forest': 8}\n",
    "dist10 = {'Computational geometry': 16, 'Generative model': 37}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = {\"0\": dist1, \"1\": dist2, \"2\": dist3, \"3\": dist4, \"5\": dist6, \"6\": dist7, \"7\": dist8, \"8\": dist9, \"9\": dist10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Computer architecture': 1,\n",
       " 'Constraint satisfaction': 44,\n",
       " 'Information privacy': 89,\n",
       " 'Knowledge extraction': 4,\n",
       " 'Logic programming': 44,\n",
       " 'Middleware': 676,\n",
       " 'Multi-agent system': 1263,\n",
       " 'OWL-S': 5,\n",
       " 'Ontology language': 27,\n",
       " 'Semantic Web': 6833,\n",
       " 'Semantic grid': 64,\n",
       " 'Semantic similarity': 1,\n",
       " 'Social network': 84,\n",
       " 'Social web': 884,\n",
       " 'User interface': 17,\n",
       " 'Web 2.0': 2069,\n",
       " 'Web service': 1424,\n",
       " 'World Wide Web': 17360}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_top_distribution_per_topic(all_dists, top=10):\n",
    "    topic_to_expert = defaultdict(list)\n",
    "    for k, v in all_dists.items():\n",
    "        for topic, weight in v.items():\n",
    "            topic_to_expert[topic].append({\"author\": k,\n",
    "                                      \"weight\": weight})\n",
    "    sorted_topic_to_expert = {}\n",
    "    for k, v in topic_to_expert.items():\n",
    "        sorted_topic_to_expert[k] = sorted(v, key=lambda item: item[\"weight\"], reverse=True)[:top]\n",
    "    return sorted_topic_to_expert\n",
    "\n",
    "\n",
    "def convert_weights_to_labels(top_distribution, label_three=0.01, label_two=0.10):\n",
    "    new_dict = {}\n",
    "    for k, v in top_distribution.items():\n",
    "        threes = v[:int(len(v) * label_three)]\n",
    "        for t in threes:\n",
    "            t[\"label\"] = 3\n",
    "        twos = v[int(len(v) * label_three) : int(len(v) * label_two)]\n",
    "        for t in twos:\n",
    "            t[\"label\"] = 2\n",
    "        ones = v[int(len(v) * label_two):]\n",
    "        for t in ones:\n",
    "            t[\"label\"] = 1\n",
    "        new_dict[k] = threes+twos+ones\n",
    "        \n",
    "    return new_dict\n",
    "# How do we now convert the weight to a label... maybe procentually\n",
    "# Maybe top 1% is relevance 3, top 10% is relevance 2, rest is relevance 1, if author is not relevant at all then 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dist = build_top_distribution_per_topic(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = convert_weights_to_labels(top_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster analysis': [{'author': '1', 'label': 1, 'weight': 74},\n",
       "  {'author': '3', 'label': 1, 'weight': 3}],\n",
       " 'Computational geometry': [{'author': '9', 'label': 1, 'weight': 16}],\n",
       " 'Computer architecture': [{'author': '0', 'label': 1, 'weight': 1}],\n",
       " 'Constraint satisfaction': [{'author': '0', 'label': 1, 'weight': 44}],\n",
       " 'Dimensionality reduction': [{'author': '1', 'label': 1, 'weight': 2}],\n",
       " 'Dynamic programming': [{'author': '6', 'label': 1, 'weight': 76}],\n",
       " 'Eye tracking': [{'author': '5', 'label': 1, 'weight': 194},\n",
       "  {'author': '6', 'label': 1, 'weight': 38}],\n",
       " 'Game theory': [{'author': '5', 'label': 1, 'weight': 1480}],\n",
       " 'Generative model': [{'author': '9', 'label': 1, 'weight': 37}],\n",
       " 'Genetic algorithm': [{'author': '3', 'label': 1, 'weight': 1}],\n",
       " 'Hierarchical clustering': [{'author': '1', 'label': 1, 'weight': 24}],\n",
       " 'Image segmentation': [{'author': '8', 'label': 1, 'weight': 130},\n",
       "  {'author': '2', 'label': 1, 'weight': 75},\n",
       "  {'author': '1', 'label': 1, 'weight': 49}],\n",
       " 'Information privacy': [{'author': '0', 'label': 1, 'weight': 89}],\n",
       " 'Knowledge extraction': [{'author': '0', 'label': 1, 'weight': 4}],\n",
       " 'Logic programming': [{'author': '0', 'label': 1, 'weight': 44}],\n",
       " 'Medical imaging': [{'author': '1', 'label': 1, 'weight': 97}],\n",
       " 'Middleware': [{'author': '0', 'label': 1, 'weight': 676}],\n",
       " 'Multi-agent system': [{'author': '0', 'label': 1, 'weight': 1263}],\n",
       " 'Multi-task learning': [{'author': '3', 'label': 1, 'weight': 7}],\n",
       " 'OWL-S': [{'author': '0', 'label': 1, 'weight': 5}],\n",
       " 'Ontology language': [{'author': '0', 'label': 1, 'weight': 27}],\n",
       " 'Random forest': [{'author': '2', 'label': 1, 'weight': 14},\n",
       "  {'author': '8', 'label': 1, 'weight': 8}],\n",
       " 'Semantic Web': [{'author': '0', 'label': 1, 'weight': 6833}],\n",
       " 'Semantic grid': [{'author': '0', 'label': 1, 'weight': 64}],\n",
       " 'Semantic similarity': [{'author': '0', 'label': 1, 'weight': 1}],\n",
       " 'Social network': [{'author': '0', 'label': 1, 'weight': 84}],\n",
       " 'Social web': [{'author': '0', 'label': 1, 'weight': 884}],\n",
       " 'Speech processing': [{'author': '1', 'label': 1, 'weight': 5}],\n",
       " 'Support vector machine': [{'author': '6', 'label': 1, 'weight': 2}],\n",
       " 'Topic model': [{'author': '3', 'label': 1, 'weight': 4}],\n",
       " 'User interface': [{'author': '0', 'label': 1, 'weight': 17},\n",
       "  {'author': '7', 'label': 1, 'weight': 10}],\n",
       " 'Wavelet transform': [{'author': '1', 'label': 1, 'weight': 7}],\n",
       " 'Wearable computer': [{'author': '6', 'label': 1, 'weight': 22}],\n",
       " 'Web 2.0': [{'author': '0', 'label': 1, 'weight': 2069}],\n",
       " 'Web service': [{'author': '0', 'label': 1, 'weight': 1424}],\n",
       " 'Wireless sensor network': [{'author': '6', 'label': 1, 'weight': 1}],\n",
       " 'World Wide Web': [{'author': '0', 'label': 1, 'weight': 17360},\n",
       "  {'author': '3', 'label': 1, 'weight': 1}]}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "lpcPfLhtGRg4",
    "daWvXqwFF_lw",
    "NmmrcDAcHtZx"
   ],
   "name": "re-ranking.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
